{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CI/CD for a Kubeflow pipeline on Vertex AI"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Learning Objectives:**\n",
    "1. Learn how to create a custom Cloud Build builder to pilote Vertex AI Pipelines\n",
    "1. Learn how to write a Cloud Build config file to build and push all the artifacts for a KFP\n",
    "1. Learn how to setup a Cloud Build GitHub trigger a new run of the Kubeflow PIpeline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this lab you will walk through authoring of a **Cloud Build** CI/CD workflow that automatically builds, deploys, and runs a Kubeflow pipeline on Vertex AI. You will also integrate your workflow with **GitHub** by setting up a trigger that starts the  workflow when a new tag is applied to the **GitHub** repo hosting the pipeline's code."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Configuring environment settings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "PROJECT_ID = !(gcloud config get-value project)\n",
    "PROJECT_ID = PROJECT_ID[0]\n",
    "REGION = \"us-central1\"\n",
    "ARTIFACT_STORE = f\"gs://{PROJECT_ID}-kfp-artifact-store\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let us make sure that the artifact store exists:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gs://qwiklabs-gcp-04-853e5675f5e8-kfp-artifact-store/\n"
     ]
    }
   ],
   "source": [
    "!gsutil ls | grep ^{ARTIFACT_STORE}/$ || gsutil mb -l {REGION} {ARTIFACT_STORE}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating the KFP CLI builder for Vertex AI"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise\n",
    "\n",
    "In the cell below, write a docker file that\n",
    "* Uses `gcr.io/deeplearning-platform-release/base-cpu` as base image\n",
    "* Install the python packages `kfp` with version `1.6.6 ` and `google-cloud-aiplatform` with version `1.3.0`\n",
    "* Starts `/bin/bash` as entrypoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting kfp-cli/Dockerfile\n"
     ]
    }
   ],
   "source": [
    "%%writefile kfp-cli/Dockerfile\n",
    "\n",
    "# TODO\n",
    "FROM gcr.io/deeplearning-platform-release/base-cpu\n",
    "RUN pip install kfp==1.6.6 google-cloud-aiplatform==1.3.0\n",
    "ENTRYPOINT [\"/bin/bash\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Build the image and push it to your project's **Container Registry**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'gcr.io/qwiklabs-gcp-04-853e5675f5e8/kfp-cli-vertex:latest'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "KFP_CLI_IMAGE_NAME = \"kfp-cli-vertex\"\n",
    "KFP_CLI_IMAGE_URI = f\"gcr.io/{PROJECT_ID}/{KFP_CLI_IMAGE_NAME}:latest\"\n",
    "KFP_CLI_IMAGE_URI"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise\n",
    "\n",
    "In the cell below, use `gcloud builds` to build the `kfp-cli-vertex` Docker image and push it to the project gcr.io registry."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/bin/bash: gcr.io/qwiklabs-gcp-04-853e5675f5e8/kfp-cli-vertex:latest: No such file or directory\n"
     ]
    }
   ],
   "source": [
    "!{KFP_CLI_IMAGE_URI}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating temporary tarball archive of 1 file(s) totalling 142 bytes before compression.\n",
      "Uploading tarball of [kfp-cli] to [gs://qwiklabs-gcp-04-853e5675f5e8_cloudbuild/source/1646386617.46244-ac76cb5a80954e03b0d5dcd5dd1b78d4.tgz]\n",
      "Created [https://cloudbuild.googleapis.com/v1/projects/qwiklabs-gcp-04-853e5675f5e8/locations/global/builds/64c36658-34b1-4956-9c5a-2a761e728236].\n",
      "Logs are available at [https://console.cloud.google.com/cloud-build/builds/64c36658-34b1-4956-9c5a-2a761e728236?project=1076138843678].\n",
      "ID                                    CREATE_TIME                DURATION  SOURCE                                                                                                     IMAGES  STATUS\n",
      "64c36658-34b1-4956-9c5a-2a761e728236  2022-03-04T09:36:58+00:00  -         gs://qwiklabs-gcp-04-853e5675f5e8_cloudbuild/source/1646386617.46244-ac76cb5a80954e03b0d5dcd5dd1b78d4.tgz  -       QUEUED\n"
     ]
    }
   ],
   "source": [
    "# COMPLETE THE COMMAND\n",
    "# https://cloud.google.com/sdk/gcloud/reference/builds/submit\n",
    "!gcloud builds submit --async --timeout 15m --tag {KFP_CLI_IMAGE_URI} kfp-cli"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Understanding the **Cloud Build** workflow.\n",
    "\n",
    "### Exercise\n",
    "\n",
    "In the cell below, you'll complete the `cloudbuild_vertex.yaml` file describing the CI/CD workflow and prescribing how environment specific settings are abstracted using **Cloud Build** variables.\n",
    "\n",
    "The CI/CD workflow automates the steps you walked through manually during `lab-02_vertex`:\n",
    "1. Builds the trainer image\n",
    "1. Compiles the pipeline\n",
    "1. Uploads and run the pipeline to the Vertex AI Pipeline environment\n",
    "1. Pushes the trainer to your project's **Container Registry**\n",
    " \n",
    "\n",
    "The **Cloud Build** workflow configuration uses both standard and custom [Cloud Build builders](https://cloud.google.com/cloud-build/docs/cloud-builders). The custom builder encapsulates **KFP CLI**. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting cloudbuild_vertex.yaml\n"
     ]
    }
   ],
   "source": [
    "%%writefile cloudbuild_vertex.yaml\n",
    "# Copyright 2021 Google LLC\n",
    "\n",
    "# Licensed under the Apache License, Version 2.0 (the \"License\"); you may not use this\n",
    "# file except in compliance with the License. You may obtain a copy of the License at\n",
    "\n",
    "# https://www.apache.org/licenses/LICENSE-2.0\n",
    "    \n",
    "# Unless required by applicable law or agreed to in writing, software \n",
    "# distributed under the License is distributed on an \"AS IS\"\n",
    "# BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either \n",
    "# express or implied. See the License for the specific language governing \n",
    "# permissions and limitations under the License.\n",
    "\n",
    "steps:\n",
    "# Build the trainer image\n",
    "# TODO\n",
    "- name: \n",
    "  id: 'Build the trainer image'\n",
    "  args: ['build', '-t', 'gcr.io/$PROJECT_ID/trainer_image_covertype_vertex:latest', '.']\n",
    "  dir: $_PIPELINE_FOLDER/trainer_image_vertex\n",
    "\n",
    "# Push the trainer image, to make it available in the compile step\n",
    "- name: 'gcr.io/cloud-builders/docker'\n",
    "  id: 'Push the trainer image'\n",
    "  args: ['push', 'gcr.io/$PROJECT_ID/trainer_image_covertype_vertex:latest']\n",
    "  dir: $_PIPELINE_FOLDER/trainer_image_vertex\n",
    "\n",
    "# Compile the pipeline\n",
    "- name: 'gcr.io/$PROJECT_ID/kfp-cli-vertex'\n",
    "  id: 'Compile the pipeline'\n",
    "  args:\n",
    "  - '-c'\n",
    "  - |\n",
    "    dsl-compile-v2 # TODO\n",
    "  env:\n",
    "  - 'PIPELINE_ROOT=gs://$PROJECT_ID-kfp-artifact-store/pipeline'\n",
    "  - 'PROJECT_ID=$PROJECT_ID'\n",
    "  - 'REGION=$_REGION'\n",
    "  - 'SERVING_CONTAINER_IMAGE_URI=us-docker.pkg.dev/vertex-ai/prediction/sklearn-cpu.0-20:latest'\n",
    "  - 'TRAINING_CONTAINER_IMAGE_URI=gcr.io/$PROJECT_ID/trainer_image_covertype_vertex:latest'\n",
    "  - 'TRAINING_FILE_PATH=gs://$PROJECT_ID-kfp-artifact-store/data/training/dataset.csv'\n",
    "  - 'VALIDATION_FILE_PATH=gs://$PROJECT_ID-kfp-artifact-store/data/validation/dataset.csv'\n",
    "  dir: pipeline_vertex\n",
    "  \n",
    "# Run the pipeline\n",
    "- name: 'gcr.io/$PROJECT_ID/kfp-cli-vertex'\n",
    "  args:\n",
    "  - '-c'\n",
    "  - |\n",
    "    python kfp-cli_vertex/run_pipeline.py  # TODO\n",
    "    \n",
    "# Push the images to Container Registry\n",
    "# TODO: List the images to be pushed to the project Docker registry\n",
    "# TODO\n",
    "images: ['gcr.io/$PROJECT_ID/trainer_image_covertype_vertex:latest']\n",
    "\n",
    "# This is required since the pipeline run overflows the default timeout\n",
    "timeout: 10800s\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Manually triggering CI/CD runs\n",
    "\n",
    "You can manually trigger **Cloud Build** runs using the [gcloud builds submit command]( https://cloud.google.com/sdk/gcloud/reference/builds/submit)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'_REGION=us-central1,_PIPELINE_FOLDER=./'"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "SUBSTITUTIONS = f\"_REGION={REGION},_PIPELINE_FOLDER=./\"\n",
    "SUBSTITUTIONS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating temporary tarball archive of 19 file(s) totalling 74.4 KiB before compression.\n",
      "Uploading tarball of [.] to [gs://qwiklabs-gcp-04-853e5675f5e8_cloudbuild/source/1646387873.746347-cd4b828943c44063a86b35bab0c9eac1.tgz]\n",
      "Created [https://cloudbuild.googleapis.com/v1/projects/qwiklabs-gcp-04-853e5675f5e8/locations/global/builds/d3aba731-9e62-48ab-921b-474ee184f3cd].\n",
      "Logs are available at [https://console.cloud.google.com/cloud-build/builds/d3aba731-9e62-48ab-921b-474ee184f3cd?project=1076138843678].\n",
      "ID                                    CREATE_TIME                DURATION  SOURCE                                                                                                      IMAGES  STATUS\n",
      "d3aba731-9e62-48ab-921b-474ee184f3cd  2022-03-04T09:57:54+00:00  -         gs://qwiklabs-gcp-04-853e5675f5e8_cloudbuild/source/1646387873.746347-cd4b828943c44063a86b35bab0c9eac1.tgz  -       QUEUED\n"
     ]
    }
   ],
   "source": [
    "!gcloud builds submit . --config cloudbuild_vertex.yaml --substitutions {SUBSTITUTIONS} --async"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Note:** If you experience issues with CloudBuild being able to access Vertex AI, you may need to run the following commands in **CloudShell**:\n",
    "\n",
    "```\n",
    "PROJECT_ID=$(gcloud config get-value project)\n",
    "PROJECT_NUMBER=$(gcloud projects list --filter=\"name=$PROJECT_ID\" --format=\"value(PROJECT_NUMBER)\")\n",
    "gcloud projects add-iam-policy-binding $PROJECT_ID \\\n",
    "    --member=\"serviceAccount:$PROJECT_NUMBER@cloudbuild.gserviceaccount.com\" \\\n",
    "    --role=\"roles/aiplatform.user\"\n",
    "gcloud iam service-accounts add-iam-policy-binding \\\n",
    "    $PROJECT_NUMBER-compute@developer.gserviceaccount.com \\\n",
    "    --member=\"serviceAccount:$PROJECT_NUMBER@cloudbuild.gserviceaccount.com\" \\\n",
    "    --role=\"roles/iam.serviceAccountUser\"\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setting up GitHub integration\n",
    "\n",
    "## Exercise\n",
    "\n",
    "In this exercise you integrate your CI/CD workflow with **GitHub**, using [Cloud Build GitHub App](https://github.com/marketplace/google-cloud-build). \n",
    "You will set up a trigger that starts the CI/CD workflow when a new tag is applied to the **GitHub** repo managing the  pipeline source code. You will use a fork of this repo as your source GitHub repository."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 1: Create a fork of this repo\n",
    "[Follow the GitHub documentation](https://help.github.com/en/github/getting-started-with-github/fork-a-repo) to fork [this repo](https://github.com/GoogleCloudPlatform/asl-ml-immersion)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 2: Create a **Cloud Build** trigger\n",
    "\n",
    "Connect the fork you created in the previous step to your Google Cloud project and create a trigger following the steps in the [Creating GitHub app trigger](https://cloud.google.com/cloud-build/docs/create-github-app-triggers) article. Use the following values on the **Edit trigger** form:\n",
    "\n",
    "|Field|Value|\n",
    "|-----|-----|\n",
    "|Name|[YOUR TRIGGER NAME]|\n",
    "|Description|[YOUR TRIGGER DESCRIPTION]|\n",
    "|Event| Tag|\n",
    "|Source| [YOUR FORK]|\n",
    "|Tag (regex)|.\\*|\n",
    "|Build Configuration|Cloud Build configuration file (yaml or json)|\n",
    "|Cloud Build configuration file location| ./notebooks/kubeflow_pipelines/cicd/solutions/cloudbuild_vertex.yaml|\n",
    "\n",
    "\n",
    "Use the following values for the substitution variables:\n",
    "\n",
    "|Variable|Value|\n",
    "|--------|-----|\n",
    "|_REGION|us-central1|\n",
    "|_PIPELINE_FOLDER|notebooks/kubeflow_pipelines/cicd/solutions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Step 3: Trigger the build\n",
    "\n",
    "To start an automated build [create a new release of the repo in GitHub](https://help.github.com/en/github/administering-a-repository/creating-releases). Alternatively, you can start the build by applying a tag using `git`. \n",
    "```\n",
    "git tag [TAG NAME]\n",
    "git push origin --tags\n",
    "```\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "On branch master\n",
      "Your branch is ahead of 'origin/master' by 1 commit.\n",
      "  (use \"git push\" to publish your local commits)\n",
      "\n",
      "Changes not staged for commit:\n",
      "  (use \"git add/rm <file>...\" to update what will be committed)\n",
      "  (use \"git checkout -- <file>...\" to discard changes in working directory)\n",
      "\n",
      "\t\u001b[31mmodified:   cloudbuild_vertex.yaml\u001b[m\n",
      "\t\u001b[31mmodified:   kfp-cli/Dockerfile\u001b[m\n",
      "\t\u001b[31mmodified:   kfp_cicd_vertex.ipynb\u001b[m\n",
      "\t\u001b[31mmodified:   ../solutions/kfp_cicd_vertex.ipynb\u001b[m\n",
      "\t\u001b[31mdeleted:    ../../pipelines/labs/kfp_pipeline.ipynb\u001b[m\n",
      "\t\u001b[31mmodified:   ../../pipelines/labs/kfp_pipeline_vertex.ipynb\u001b[m\n",
      "\t\u001b[31mmodified:   ../../pipelines/labs/kfp_pipeline_vertex_prebuilt.ipynb\u001b[m\n",
      "\t\u001b[31mmodified:   ../../pipelines/labs/pipeline_vertex/pipeline.py\u001b[m\n",
      "\t\u001b[31mmodified:   ../../pipelines/labs/pipeline_vertex/training_lightweight_component.py\u001b[m\n",
      "\t\u001b[31mmodified:   ../../pipelines/labs/pipeline_vertex/tuning_lightweight_component.py\u001b[m\n",
      "\t\u001b[31mmodified:   ../../pipelines/solutions/kfp_pipeline_vertex_prebuilt.ipynb\u001b[m\n",
      "\t\u001b[31mmodified:   ../../walkthrough/labs/kfp_walkthrough_vertex.ipynb\u001b[m\n",
      "\n",
      "Untracked files:\n",
      "  (use \"git add <file>...\" to include in what will be committed)\n",
      "\n",
      "\t\u001b[31m../../pipelines/labs/covertype_kfp_pipeline.json\u001b[m\n",
      "\t\u001b[31m../../pipelines/labs/pipeline_vertex/pipeline_prebuilt.py\u001b[m\n",
      "\t\u001b[31m../../pipelines/solutions/covertype_kfp_pipeline.json\u001b[m\n",
      "\t\u001b[31m../../walkthrough/labs/config.yaml\u001b[m\n",
      "\t\u001b[31m../../walkthrough/labs/training_app/\u001b[m\n",
      "\n",
      "no changes added to commit (use \"git add\" and/or \"git commit -a\")\n"
     ]
    }
   ],
   "source": [
    "!git add "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After running the command above, a build should have been automatically triggered, which you should able to inspect [here](https://console.cloud.google.com/cloud-build/builds)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Copyright 2021 Google LLC\n",
    "\n",
    "Licensed under the Apache License, Version 2.0 (the \"License\");\n",
    "you may not use this file except in compliance with the License.\n",
    "You may obtain a copy of the License at\n",
    "\n",
    "    https://www.apache.org/licenses/LICENSE-2.0\n",
    "\n",
    "Unless required by applicable law or agreed to in writing, software\n",
    "distributed under the License is distributed on an \"AS IS\" BASIS,\n",
    "WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
    "See the License for the specific language governing permissions and\n",
    "limitations under the License."
   ]
  }
 ],
 "metadata": {
  "environment": {
   "kernel": "python3",
   "name": "tf2-gpu.2-6.m90",
   "type": "gcloud",
   "uri": "gcr.io/deeplearning-platform-release/tf2-gpu.2-6:m90"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
