name: Train
inputs:
- {name: training_clean_file_path, type: String}
- {name: validation_clean_file_path, type: String}
- {name: model_dir, type: String}
implementation:
  container:
    image: python:3.9
    command:
    - sh
    - -c
    - |2

      if ! [ -x "$(command -v pip)" ]; then
          python3 -m ensurepip || python3 -m ensurepip --user || apt-get install python3-pip
      fi

      PIP_DISABLE_PIP_VERSION_CHECK=1 python3 -m pip install --quiet     --no-warn-script-location 'google-cloud-bigquery' 'sklearn' 'tensorflow' 'tensorflow_datasets' 'pandas' 'fsspec' 'gcsfs' 'pyarrow' 'fastparquet' 'kfp==1.8.10' && "$0" "$@"
    - sh
    - -ec
    - |
      program_path=$(mktemp -d)
      printf "%s" "$0" > "$program_path/ephemeral_component.py"
      python3 -m kfp.v2.components.executor_main                         --component_module_path                         "$program_path/ephemeral_component.py"                         "$@"
    - "\nimport kfp\nfrom kfp.v2 import dsl\nfrom kfp.v2.dsl import *\nfrom typing\
      \ import *\n\ndef train(training_clean_file_path: str,\n          validation_clean_file_path:\
      \ str,\n          model_dir: str):    \n    # TODO: Move to train.py script\n\
      \    import pandas as pd\n    import numpy as np\n    import logging\n    from\
      \ typing import Dict, Text\n    import tensorflow as tf\n    from tensorflow.keras\
      \ import Model\n    from tensorflow.keras import optimizers as opt\n    from\
      \ tensorflow.keras.layers import Embedding, multiply, concatenate, Flatten,\
      \ Input, Dense\n\n    logging.info(\"Reading train data...\")    \n    df_train\
      \ = pd.read_csv(training_clean_file_path)\n    logging.info(\"Reading valid\
      \ data...\")\n    df_val = pd.read_csv(validation_clean_file_path)\n\n    num_unique_users=len(set(list(df_train.userId.unique())\
      \ + list(df_val.userId.unique())))\n    num_unique_movies=len(set(list(df_train.movieId.unique())\
      \ + list(df_val.movieId.unique())))\n\n    users_input = Input(shape=(1,), name=\"\
      users_input\")\n    users_embedding = Embedding(num_unique_users + 1, 50, name=\"\
      users_embeddings\")(users_input)\n    users_bias = Embedding(num_unique_users\
      \ + 1, 1, name=\"users_bias\")(users_input)\n\n    movies_input = Input(shape=(1,),\
      \ name=\"movies_input\")\n    movies_embedding = Embedding(num_unique_movies\
      \ + 1, 50, name=\"movies_embedding\")(movies_input)\n    movies_bias = Embedding(num_unique_movies\
      \ + 1, 1, name=\"movies_bias\")(movies_input)\n\n    dot_product_users_movies\
      \ = multiply([users_embedding, movies_embedding])\n    input_terms = dot_product_users_movies\
      \ + users_bias + movies_bias\n    input_terms = Flatten(name=\"fl_inputs\")(input_terms)\n\
      \    output = Dense(1, activation=\"relu\", name=\"output\")(input_terms)\n\
      \    model = Model(inputs=[users_input, movies_input], outputs=output)\n\n \
      \   opt_adam = opt.Adam(lr = 0.005)\n    model.compile(optimizer=opt_adam, loss=\
      \ ['mse'], metrics=['mean_absolute_error'])\n\n    model.fit(x=[df_train.userId,\
      \ df_train.movieId], \n              y=df_train.rating, \n              batch_size=512,\
      \ \n              epochs=1, \n              verbose=1, \n              validation_data=([df_val.userId,\
      \ df_val.movieId], df_val.rating))\n\n    # save model\n    tf.saved_model.save(model,\
      \ model_dir)\n\n"
    args:
    - --executor_input
    - {executorInput: null}
    - --function_to_execute
    - train
