name: Data prep
inputs:
- {name: training_file_path, type: String}
- {name: validation_file_path, type: String}
- {name: training_clean_file_path, type: String}
- {name: validation_clean_file_path, type: String}
implementation:
  container:
    image: python:3.9
    command:
    - sh
    - -c
    - |2

      if ! [ -x "$(command -v pip)" ]; then
          python3 -m ensurepip || python3 -m ensurepip --user || apt-get install python3-pip
      fi

      PIP_DISABLE_PIP_VERSION_CHECK=1 python3 -m pip install --quiet     --no-warn-script-location 'google-cloud-bigquery' 'tensorflow' 'tensorflow_datasets' 'pandas' 'fsspec' 'gcsfs' 'pyarrow' 'fastparquet' 'kfp==1.8.10' && "$0" "$@"
    - sh
    - -ec
    - |
      program_path=$(mktemp -d)
      printf "%s" "$0" > "$program_path/ephemeral_component.py"
      python3 -m kfp.v2.components.executor_main                         --component_module_path                         "$program_path/ephemeral_component.py"                         "$@"
    - |2+

      import kfp
      from kfp.v2 import dsl
      from kfp.v2.dsl import *
      from typing import *

      def data_prep(training_file_path:str,
                    validation_file_path:str,
                    training_clean_file_path:str,
                    validation_clean_file_path:str):
          import pandas as pd
          import numpy as np

          df_train = pd.read_csv(training_file_path)
          df_val = pd.read_csv(validation_file_path)

          movies_ids = list(set(list(df_train.movieId.unique()) + list(df_val.movieId.unique())))
          users_ids = list(set(list(df_train.userId.unique()) + list(df_val.userId.unique())))

          dict_movies = dict(zip(movies_ids, range(len(movies_ids)) ))
          dict_users = dict(zip(users_ids, range(len(users_ids)) ))

          df_train["movieId"] = df_train["movieId"].map(dict_movies)
          df_val["movieId"] = df_val["movieId"].map(dict_movies)

          df_train["userId"] = df_train["userId"].map(dict_users)
          df_val["userId"] = df_val["userId"].map(dict_users)

          col = ["userId", "movieId", "rating"]
          df_train[col] = df_train[col].astype(np.float32)
          df_val[col] = df_val[col].astype(np.float32)

          # save to bucket
          df_train.to_csv(training_clean_file_path, index=False)
          df_val.to_csv(validation_clean_file_path, index=False)

    args:
    - --executor_input
    - {executorInput: null}
    - --function_to_execute
    - data_prep
